# Quick Start Guide - EDA Pipeline

## ğŸš€ Getting Started (5 minutes)

### Step 1: Verify Setup
```powershell
python test_eda_setup.py
```
This checks if all dependencies are installed correctly.

### Step 2: Run Complete Analysis
```powershell
python run_eda.py
```
This will:
- âœ“ Load data from Firebase
- âœ“ Clean and preprocess
- âœ“ Perform sentiment analysis
- âœ“ Generate 18+ visualizations
- âœ“ Create HTML report

**Estimated time**: 5-15 minutes (depends on data size)

### Step 3: View Results
Open the generated report:
```powershell
# Windows
start analysis_output/analysis_report.html

# Or manually navigate to:
# analysis_output/analysis_report.html
```

---

## ğŸ“Š What You'll Get

### Cleaned Data
- `cleaned_data/cleaned_posts.csv` - Ready-to-analyze posts
- `cleaned_data/posts_with_sentiment.csv` - Posts with sentiment scores

### Visualizations (18 total)

#### Temporal Trends (5 charts)
1. Sentiment trends over years
2. Post volume by sentiment category
3. Positive posts percentage by year
4. Year-over-year sentiment changes
5. Word clouds by year

#### COVID Comparison (6 charts)
1. Sentiment distribution comparison
2. VADER score comparison (box + violin + bar)
3. Post volume over time
4. Detailed score distributions (histogram + KDE + CDF)
5. Subreddit distribution changes
6. Word cloud comparison

#### Overall EDA (6 charts)
1. Overall sentiment distribution (posts vs comments)
2. Sentiment by subreddit (top 20)
3. Top TF-IDF terms
4. Topic modeling (5 topics)
5. Subreddit TF-IDF comparison
6. Medical terms analysis + word cloud

### Report
- `analysis_output/analysis_report.html` - Interactive HTML report with all visualizations

---

## âš™ï¸ Common Commands

### Run Individual Analyses

```powershell
# Just clean the data
python data_cleaning.py

# Just sentiment analysis
python sentiment_analysis.py

# Just temporal trends
python temporal_analysis.py

# Just COVID comparison
python covid_comparison.py

# Just overall EDA
python overall_eda.py
```

### Custom Analysis Example

```python
# custom_analysis.py
from data_cleaning import DataCleaner
from sentiment_analysis import SentimentAnalyzer

# Load and prepare data
cleaner = DataCleaner()
posts_df, comments_df = cleaner.run_full_cleaning(save_output=False)

analyzer = SentimentAnalyzer()
posts_df, _ = analyzer.run_full_analysis(posts_df, comments_df, save_output=False)

# Your custom code here
# Filter posts from specific subreddit
preeclampsia_posts = posts_df[posts_df['subreddit'] == 'preeclampsia']

# Analyze sentiment over time
yearly_sentiment = preeclampsia_posts.groupby('year')['sentiment_compound'].mean()
print(yearly_sentiment)
```

---

## ğŸ” Analyses Checklist

### âœ… Temporal Trends
- [x] Sentiment trend over the years
- [x] Post volume over the years (colored by sentiment)
- [x] % positive posts by year
- [x] Year over year sentiment change
- [x] Year over year change in wordcloud

### âœ… Pre vs Post COVID
- [x] Sentiment distribution
- [x] Avg VADER score
- [x] Post volume difference
- [x] Sentiment score distributions
- [x] Post distribution across subreddits
- [x] Wordcloud difference

### âœ… Overall
- [x] Sentiment distribution
- [x] Avg sentiment by subreddit
- [x] TF-IDF inclusion â†’ topic modeling
- [x] Subreddit comparison
- [x] Wordcloud of medical terms being used

---

## ğŸ“ Output Structure

```
analysis_output/
â”œâ”€â”€ analysis_report.html          # ğŸ“„ Main report
â”œâ”€â”€ temporal/                     # ğŸ“ˆ 5 visualizations
â”‚   â”œâ”€â”€ sentiment_trend_over_years.png
â”‚   â”œâ”€â”€ post_volume_by_sentiment.png
â”‚   â”œâ”€â”€ positive_percentage_by_year.png
â”‚   â”œâ”€â”€ yoy_sentiment_change.png
â”‚   â””â”€â”€ wordcloud_by_year.png
â”œâ”€â”€ covid_comparison/             # ğŸ¦  6 visualizations
â”‚   â”œâ”€â”€ sentiment_distribution_comparison.png
â”‚   â”œâ”€â”€ vader_score_comparison.png
â”‚   â”œâ”€â”€ post_volume_comparison.png
â”‚   â”œâ”€â”€ sentiment_score_distributions.png
â”‚   â”œâ”€â”€ subreddit_distribution_comparison.png
â”‚   â””â”€â”€ wordcloud_comparison.png
â””â”€â”€ overall/                      # ğŸ”¬ 6 visualizations + 3 CSVs
    â”œâ”€â”€ overall_sentiment_distribution.png
    â”œâ”€â”€ sentiment_by_subreddit.png
    â”œâ”€â”€ tfidf_top_terms.png
    â”œâ”€â”€ topic_modeling.png
    â”œâ”€â”€ subreddit_tfidf_comparison.png
    â”œâ”€â”€ medical_terms_analysis.png
    â”œâ”€â”€ sentiment_by_subreddit.csv
    â”œâ”€â”€ tfidf_scores.csv
    â””â”€â”€ medical_terms_frequency.csv

cleaned_data/
â”œâ”€â”€ cleaned_posts.csv
â”œâ”€â”€ cleaned_comments.csv
â”œâ”€â”€ posts_with_sentiment.csv
â”œâ”€â”€ comments_with_sentiment.csv
â”œâ”€â”€ data_summary.json
â””â”€â”€ sentiment_summary.json
```

---

## ğŸ› Troubleshooting

### Error: "No posts data available"
**Solution**: Run data collection first:
```powershell
python data_collector_praw.py
```

### Error: "Missing required columns"
**Solution**: Ensure data cleaning ran successfully. Check `cleaned_data/` folder exists.

### Error: ImportError for packages
**Solution**: Install dependencies:
```powershell
pip install -r requirements.txt
```

### Visualizations not generating
**Solution**: Check if matplotlib backend is configured:
```python
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
```

### Firebase connection error
**Solution**: 
1. Check `.env` file has correct `FIREBASE_DATABASE_URL`
2. Verify `pre-eclampsia-analysis-firebase-adminsdk-*.json` exists

---

## ğŸ’¡ Tips

1. **First Run**: May take 10-15 minutes depending on data size
2. **Subsequent Runs**: Use cached cleaned data for faster analysis
3. **Memory**: Large datasets may require 4GB+ RAM
4. **Visualizations**: All saved at 300 DPI for publication quality
5. **Report**: HTML report can be shared - all images are embedded/linked

---

## ğŸ“Š Key Metrics in Report

- **Total Posts**: Count of analyzed posts
- **Total Comments**: Count of analyzed comments
- **Subreddits**: Number of unique communities
- **Average Sentiment**: Overall compound score
- **Date Range**: Start to end of data collection
- **COVID Impact**: Pre vs post pandemic comparison

---

## ğŸ¯ Next Steps After EDA

1. **Review HTML Report**: Get overview of all findings
2. **Check CSVs**: Use cleaned data for custom analyses
3. **Examine Topics**: Review LDA topics for themes
4. **Medical Terms**: Check frequency of clinical terminology
5. **Subreddit Insights**: Identify most positive/negative communities
6. **Time Patterns**: Note sentiment changes over years

---

## âœ… Verification Checklist

Before running analysis, ensure:
- [ ] Firebase connection configured
- [ ] `.env` file exists with correct values
- [ ] Virtual environment activated
- [ ] All dependencies installed (`pip install -r requirements.txt`)
- [ ] Data has been collected (posts exist in Firebase)
- [ ] Sufficient disk space (500MB+ recommended)

After analysis, verify:
- [ ] `cleaned_data/` folder created
- [ ] `analysis_output/` folder with 3 subfolders
- [ ] 18+ PNG files generated
- [ ] `analysis_report.html` opens in browser
- [ ] No error messages in console

---

**Ready to analyze?** Run: `python run_eda.py`
